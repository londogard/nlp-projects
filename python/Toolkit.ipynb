{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVynXr_l5YlJ",
        "colab_type": "text"
      },
      "source": [
        "## Text Cleaning Swedish Tweets\n",
        "We begin by importing and installing all necessary libraries. We got some extras for later usage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "su3xLG_p7kCC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!pip install gensim --upgrade\n",
        "!pip install transformers\n",
        "!pip install fse"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auHtf9sUMMnE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # dat\n",
        "\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "import os\n",
        "import random \n",
        "import operator \n",
        "import regex as re\n",
        "\n",
        "\"\"\"\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "# fastai\n",
        "from fastai import *\n",
        "from fastai.text import *\n",
        "from fastai.callbacks import *\n",
        "\n",
        "# transformers\n",
        "from transformers import PreTrainedModel, PreTrainedTokenizer, PretrainedConfig\n",
        "\n",
        "from transformers import pipeline\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification, AutoModelWithLMHead, AutoModel\n",
        "from transformers import AutoTokenizer, TFAutoModelForTokenClassification\n",
        "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig\n",
        "\"\"\"\n",
        "\n",
        "# gensim + fasttext\n",
        "from gensim.models.fasttext import FastText, load_facebook_vectors\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "# import fastai\n",
        "# import transformers\n",
        "import spacy"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Agdl5-tx7KTY",
        "colab_type": "code",
        "outputId": "0bdc9859-431e-4972-92bc-49f86374fc98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# print('fastai version :', fastai.__version__)\n",
        "# print('transformers version :', transformers.__version__)\n",
        "print('spacy version :', spacy.__version__)\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"KB/bert-base-swedish-cased-ner\")\n",
        "# model = AutoModelForTokenClassification.from_pretrained(\"KB/bert-base-swedish-cased-ner\")\t\t\t"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "spacy version : 2.2.4\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUQ_Olz559-p",
        "colab_type": "text"
      },
      "source": [
        "## Reading the data\n",
        "Let's begin by inspecting the data to understand it further"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YUv3i2FMZhm",
        "colab_type": "code",
        "outputId": "1de8c2dc-56c5-49a0-c8bd-2ed6ec0dac8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        }
      },
      "source": [
        "# Make sure format is raw,y\n",
        "FILENAME = \"../datasets/swedish_tweet_combined.csv\"\n",
        "\n",
        "df = pd.read_csv(FILENAME)\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "(36680, 2)\n"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                                 raw         y\n0  RT @Carolinafarraj: Fick h√∂ra idag 'hur k√§nner...  Negative\n1  Nice att vakna halv 3 p√• natten med en snustor...  Negative\n2  RT @DKristoffersson: David Luiz √§r rolig p√• In...  Positive\n3  RT @Chiyokosmet: Nej, jag bryr inte om vem du ...  Positive\n4  RT @petterbristav: Det har l√§ckt ut nakenbilde...   Neutral",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>raw</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>RT @Carolinafarraj: Fick h√∂ra idag 'hur k√§nner...</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Nice att vakna halv 3 p√• natten med en snustor...</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>RT @DKristoffersson: David Luiz √§r rolig p√• In...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>RT @Chiyokosmet: Nej, jag bryr inte om vem du ...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>RT @petterbristav: Det har l√§ckt ut nakenbilde...</td>\n      <td>Neutral</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJwgPCHh7Stp",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing allowing our Word Embeddings to actually cover more\n",
        "We want to cover the data as well as possible through our embeddings, else the feature / word is completely lost.\n",
        "\n",
        "To begin with we'll look at the vocabs. Both word & characters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbO5Ur8M4Wr1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_vocab(sentences, verbose =  True):\n",
        "    \"\"\"\n",
        "    :param sentences: list of list of words\n",
        "    :return: dictionary of words and their count\n",
        "    \"\"\"\n",
        "    vocab = {}\n",
        "    for sentence in tqdm(sentences, disable = (not verbose)):\n",
        "        for word in sentence:\n",
        "            try:\n",
        "                vocab[word] += 1\n",
        "            except KeyError:\n",
        "                vocab[word] = 1\n",
        "    return vocab"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIE4WDCS0VkA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_char_vocab(sentences, verbose =  True):\n",
        "    \"\"\"\n",
        "    :param sentences: list of list of words\n",
        "    :return: dictionary of words and their count\n",
        "    \"\"\"\n",
        "    vocab = {}\n",
        "    for sentence in tqdm(sentences, disable = (not verbose)):\n",
        "        for word in sentence:\n",
        "          for char in word:\n",
        "            try:\n",
        "                vocab[char] += 1\n",
        "            except KeyError:\n",
        "                vocab[char] = 1\n",
        "    return vocab"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9jSks5T650y",
        "colab_type": "text"
      },
      "source": [
        "### Inspecting our vocab\n",
        "Let's look at how good we cover our words with these methods!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sE-ABrJD0gL7",
        "colab_type": "code",
        "outputId": "00812e62-ce1b-4f2b-8e88-a35e1f121b6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "sentences = df[\"raw\"].progress_apply(lambda x: x.split()).values\n",
        "vocab = build_vocab(sentences)\n",
        "print()\n",
        "print({k: vocab[k] for k in list(vocab)[:5]})"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36680/36680 [00:00<00:00, 127130.37it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36680/36680 [00:00<00:00, 152065.62it/s]\n{'RT': 12726, '@Carolinafarraj:': 58, 'Fick': 104, 'h√∂ra': 88, 'idag': 354}\n\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTUh-3a_0qID",
        "colab_type": "code",
        "outputId": "e1adf2cd-17df-48aa-c662-69b2d76b8c54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "char_vocab = build_char_vocab(sentences)\n",
        "print()\n",
        "print({k: char_vocab[k] for k in list(char_vocab)[-10:]})\n",
        "print({k: char_vocab[k] for k in list(char_vocab)[:10]})"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36680/36680 [00:00<00:00, 64041.68it/s]\n{'üë∫': 1, '‚Ñ¢': 2, 'ƒÅ': 2, '≈õ': 1, 'ƒ´': 1, '≈´': 1, 'üá´': 1, 'üá∑': 1, 'ƒá': 1, 'üêª': 1}\n{'R': 20832, 'T': 22687, '@': 33486, 'C': 4685, 'a': 247282, 'r': 214951, 'o': 122662, 'l': 140640, 'i': 150416, 'n': 201214}\n\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgTnrJrj7ODr",
        "colab_type": "text"
      },
      "source": [
        "### Loading our Word2Vec\n",
        "Let's load the W2V and then check the coverage!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2z65JwZt-Iuj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL_PATH = \"../models/cc.sv.100.bin\"\n",
        "f_vectors = load_facebook_vectors(MODEL_PATH) # load_facebook_vectors('cc.sv.300.bin.gz')"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psihTzJX7eJq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def check_coverage(vocab,embeddings_index):\n",
        "    a = {}\n",
        "    oov = {}\n",
        "    k = 0\n",
        "    i = 0\n",
        "    for word in tqdm(vocab):\n",
        "        try:\n",
        "            a[word] = embeddings_index[word]\n",
        "            k += vocab[word]\n",
        "        except:\n",
        "            oov[word] = vocab[word]\n",
        "            i += vocab[word]\n",
        "            pass\n",
        "\n",
        "    print('Found embeddings for {:.2%} of vocab'.format(len(a) / len(vocab)))\n",
        "    print('Found embeddings for  {:.2%} of all text'.format(k / (k + i)))\n",
        "    sorted_x = sorted(oov.items(), key=operator.itemgetter(1))[::-1]\n",
        "\n",
        "    return sorted_x"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viS0MXJdCIpS",
        "colab_type": "code",
        "outputId": "958788a0-1106-4dbd-a9e8-2f63f02acb5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "oov = check_coverage(vocab, f_vectors.vocab)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 99887/99887 [00:00<00:00, 307338.26it/s]Found embeddings for 39.04% of vocab\nFound embeddings for  77.00% of all text\n\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeCDz7HN7T9q",
        "colab_type": "text"
      },
      "source": [
        "### Coverage\n",
        "Pretty okay for no changes applied, covering ~ 77% of the text (but only 39% of the vocab! :O)\n",
        "\n",
        "We can simply inspect the OOV words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sq-qIMvCRLP",
        "colab_type": "code",
        "outputId": "07da5540-aa82-44be-d551-482e2661faa5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "oov[:10]"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "[('#svpol', 1271),\n (':)', 729),\n ('#dinr√∂st', 655),\n ('&amp;', 558),\n ('#val2014', 530),\n ('Egots', 316),\n (';)', 242),\n ('@Emmywin:', 217),\n ('#08pol', 214),\n ('@niklassvensson:', 200)]"
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6l_LPx7A2OP",
        "colab_type": "text"
      },
      "source": [
        "Looking at the data it seems as if the embeddings are lower-cased. By looking at them you can see this yourself, it's actually only lower-case words. \n",
        "\n",
        "Let us fix this by lowering all text (shouldn't loose way to much context by this - but important to keep in mind during cleaning!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGBUW8Lzy-5o",
        "colab_type": "code",
        "outputId": "11612a74-5906-46bd-c3bc-9b8548e158e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "df['TweetText'] = df['TweetText'].progress_apply(lambda x: x.lower())\n",
        "sentences = df[\"TweetText\"].apply(lambda x: x.split())\n",
        "vocab = build_vocab(sentences)\n",
        "oov = check_coverage(vocab, f_vectors.vocab)\n",
        "\n",
        "oov[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36680/36680 [00:00<00:00, 540415.38it/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36680/36680 [00:00<00:00, 187809.17it/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 92393/92393 [00:00<00:00, 726411.08it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found embeddings for 46.43% of vocab\n",
            "Found embeddings for  82.60% of all text\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('&amp;', 558),\n",
              " ('‚Ä¶', 496),\n",
              " ('ja,', 263),\n",
              " ('@emmywin:', 217),\n",
              " ('@niklassvensson:', 200),\n",
              " ('http://‚Ä¶', 169),\n",
              " ('@expressen:', 160),\n",
              " ('nej,', 160),\n",
              " ('@ahedenstedt:', 153),\n",
              " (\"'det\", 152)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXY-d5XCBi-m",
        "colab_type": "text"
      },
      "source": [
        "**Gains**\n",
        "\n",
        "10 % units gained in vocab coverage and almost 20 % units gained in text coverage! That's _really_ good for such a simple thing to do. Looking at the top OOV we can still see some issues.\n",
        "\n",
        "1. Retweets & mentions\n",
        "2. http/https websites\n",
        "3. html-code (`&amp` etc)\n",
        "4. bad tokenization (e.g. `'det`)\n",
        "\n",
        "Let's start by fixing a few of these. Namely retweet-pattern & removing punctuation (using subword embeddings such as fastText would allow us to keep these better)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zl4Ox8iM5hNA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "retweet_pattern = re.compile('rt \\S+: ')\n",
        "punct_pattern = re.compile('([!\"$%&\\'()*+,-./:;<=>?[\\\\]^_`{|}~])')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRtw8sqp0xCw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_text(text):\n",
        "  text = retweet_pattern.sub('', text)\n",
        "  text = at_pattern.sub(' @ anv√§ndare', text)\n",
        "  text = http_pattern.sub('l√§nk ', text)\n",
        "  text = punct_pattern.sub(' ', text)\n",
        "  text = text.replace(' #', ' # ')\n",
        "  text = text.replace(':)', 'glad')\n",
        "  text = text.replace(';)', 'glad')\n",
        "  text = text.replace(':-)', 'glad')\n",
        "  text = text.replace('&amp;', '&')\n",
        "  #for punct in '?!.,\"#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~' + '‚Äú‚Äù‚Äô':\n",
        "  #      text = text.replace(punct, '')\n",
        "  return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jn1jYOwy0m0d",
        "colab_type": "code",
        "outputId": "2a42484d-6d6d-455e-c712-c2fe4d86b389",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "source": [
        "df['TweetText'] = df['TweetText'].progress_apply(lambda x: clean_text(x))\n",
        "sentences = df[\"TweetText\"].apply(lambda x: x.split())\n",
        "vocab = build_vocab(sentences)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/36680 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            " 19%|‚ñà‚ñâ        | 6912/36680 [00:00<00:00, 69112.32it/s]\u001b[A\u001b[A\n",
            "\n",
            " 38%|‚ñà‚ñà‚ñà‚ñä      | 13834/36680 [00:00<00:00, 69143.67it/s]\u001b[A\u001b[A\n",
            "\n",
            " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 20720/36680 [00:00<00:00, 69056.91it/s]\u001b[A\u001b[A\n",
            "\n",
            " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 27843/36680 [00:00<00:00, 69691.49it/s]\u001b[A\u001b[A\n",
            "\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36680/36680 [00:00<00:00, 69404.87it/s]\n",
            "\n",
            "\n",
            "  0%|          | 0/36680 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36680/36680 [00:00<00:00, 198765.74it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5S_JasZa6s0e",
        "colab_type": "code",
        "outputId": "a26a71b6-5a40-4806-dbb6-539791c223ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "oov = check_coverage(vocab, f_vectors.vocab)\n",
        "oov[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 53503/53503 [00:00<00:00, 652081.11it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found embeddings for 75.42% of vocab\n",
            "Found embeddings for  95.43% of all text\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('‚Ä¶', 713),\n",
              " ('08pol', 218),\n",
              " ('http‚Ä¶', 116),\n",
              " ('anv√§ndare‚Ä¶', 112),\n",
              " ('dinroest', 106),\n",
              " ('ht‚Ä¶', 92),\n",
              " ('htt‚Ä¶', 85),\n",
              " ('jobbvalet', 76),\n",
              " ('hypnostillst√•nd', 70),\n",
              " ('twittpuck', 64)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSqknt174EGX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "at_pattern = re.compile('\\s(@[\\w_-]+):?')\n",
        "http_pattern = re.compile('https?:\\S+')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Toolkit.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}